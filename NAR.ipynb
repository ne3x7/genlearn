{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats as sts\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.despine()\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35 по phi, 5 по p\n",
    "\n",
    "10 по v, 40 по p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.vstack([pd.read_csv(f'data_sparse/{fname}').drop('t', 1).values \\\n",
    "                               for fname in os.listdir('data_sparse') if fname != '.DS_Store']),\n",
    "                    columns=['v', 'phi', 'p', 'q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.DataFrame(np.vstack([pd.read_csv(f'data_test/{fname}').drop('t', 1).values \\\n",
    "                                    for fname in os.listdir('data_test') if fname != '.DS_Store']),\n",
    "                         columns=['v', 'phi', 'p', 'q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, True, True, figsize=(20,10))\n",
    "fig.tight_layout()\n",
    "for ax, pair in zip(axes.flatten(), [('p', 'v'), ('p', 'phi'), ('q', 'v'), ('q', 'phi')]):\n",
    "    mtx = np.array([[data[pair[0]].shift(x).corr(data[pair[1]].shift(y)) for y in range(50)] for x in range(50)])\n",
    "    mtx_inv = np.linalg.inv(mtx)\n",
    "    sns.heatmap(mtx_inv, cmap='RdYlBu', ax=ax)\n",
    "    ax.set_xlabel(pair[1] + ' shifted')\n",
    "    ax.set_ylabel(pair[0] + ' shifted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pd.read_csv(f'data_sparse/{fname}').drop('t', 1) \\\n",
    "        for fname in os.listdir('data_sparse') if fname != '.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(20,20))\n",
    "varnames = ['$V$', '$\\\\varphi$', '$P$', '$Q$']\n",
    "varidx = ['v', 'phi', 'p', 'q']\n",
    "for i, (iname, iidx, axrow) in enumerate(zip(varnames, varidx, axes)):\n",
    "    for j, (jname, jidx, ax) in enumerate(zip(varnames, varidx, axrow)):\n",
    "        lags = range(1, 150)\n",
    "        corrs_all = list()\n",
    "        for df in data:\n",
    "            corrs = list()\n",
    "            for lag in lags:\n",
    "                corrs.append(df[iidx].corr(df[jidx].shift(lag)))\n",
    "            corrs_all.append(corrs)\n",
    "        corrs = np.sum(corrs_all, axis=0) / len(data)\n",
    "        ax.plot(lags, corrs)\n",
    "        bounds = ax.get_xbound()\n",
    "        ax.hlines([sts.norm.cdf(0.95), -sts.norm.cdf(0.95)] / np.sqrt(len(data)),\n",
    "                  *ax.get_xbound())\n",
    "        ax.hlines([sts.norm.cdf(0.99), -sts.norm.cdf(0.99)] / np.sqrt(len(data)),\n",
    "                  *ax.get_xbound(), linestyles='dashed')\n",
    "        ax.vlines(30, sts.norm.cdf(0.99) / np.sqrt(len(data)), -sts.norm.cdf(0.99) / np.sqrt(len(data)), 'r')\n",
    "        if i == 3:\n",
    "            ax.set_xlabel('Lag')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('Correlation')\n",
    "        ax.set_title(iname + ' / ' + jname)\n",
    "        ax.set_xlim(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(20,20))\n",
    "varnames = ['$V$', '$\\\\varphi$', '$P$', '$Q$']\n",
    "varidx = ['v', 'phi', 'p', 'q']\n",
    "for i, (iname, iidx, axrow) in enumerate(zip(varnames, varidx, axes)):\n",
    "    for j, (jname, jidx, ax) in enumerate(zip(varnames, varidx, axrow)):\n",
    "        lags = range(1, 150)\n",
    "        corrs_all = list()\n",
    "        for df in data:\n",
    "            corrs = list()\n",
    "            for lag in lags:\n",
    "                corrs.append(df[iidx].corr(df[jidx].shift(lag).apply(lambda x: np.sin(x))))\n",
    "            corrs_all.append(corrs)\n",
    "        corrs = np.sum(corrs_all, axis=0) / len(data)\n",
    "        ax.plot(lags, corrs)\n",
    "        bounds = ax.get_xbound()\n",
    "        ax.hlines([sts.norm.cdf(0.95), -sts.norm.cdf(0.95)] / np.sqrt(len(data)),\n",
    "                  *ax.get_xbound())\n",
    "        ax.hlines([sts.norm.cdf(0.99), -sts.norm.cdf(0.99)] / np.sqrt(len(data)),\n",
    "                  *ax.get_xbound(), linestyles='dashed')\n",
    "        ax.vlines(30, sts.norm.cdf(0.99) / np.sqrt(len(data)), -sts.norm.cdf(0.99) / np.sqrt(len(data)), 'r')\n",
    "        if i == 3:\n",
    "            ax.set_xlabel('Lag')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('Correlation')\n",
    "        ax.set_title(iname + ' / sin(' + jname + ')')\n",
    "        ax.set_xlim(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(20,20))\n",
    "varnames = ['$V$', '$\\\\varphi$', '$P$', '$Q$']\n",
    "varidx = ['v', 'phi', 'p', 'q']\n",
    "for i, (iname, iidx, axrow) in enumerate(zip(varnames, varidx, axes)):\n",
    "    for j, (jname, jidx, ax) in enumerate(zip(varnames, varidx, axrow)):\n",
    "        lags = range(1, 150)\n",
    "        corrs_all = list()\n",
    "        for df in data:\n",
    "            corrs = list()\n",
    "            for lag in lags:\n",
    "                corrs.append(df[iidx].corr(df[jidx].shift(lag).apply(lambda x: np.exp(x))))\n",
    "            corrs_all.append(corrs)\n",
    "        corrs = np.sum(corrs_all, axis=0) / len(data)\n",
    "        ax.plot(lags, corrs)\n",
    "        bounds = ax.get_xbound()\n",
    "        ax.hlines([sts.norm.cdf(0.95), -sts.norm.cdf(0.95)] / np.sqrt(len(data)),\n",
    "                  *ax.get_xbound())\n",
    "        ax.hlines([sts.norm.cdf(0.99), -sts.norm.cdf(0.99)] / np.sqrt(len(data)),\n",
    "                  *ax.get_xbound(), linestyles='dashed')\n",
    "        ax.vlines(30, sts.norm.cdf(0.99) / np.sqrt(len(data)), -sts.norm.cdf(0.99) / np.sqrt(len(data)), 'r')\n",
    "        if i == 3:\n",
    "            ax.set_xlabel('Lag')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('Correlation')\n",
    "        ax.set_title(iname + ' / sin(' + jname + ')')\n",
    "        ax.set_xlim(bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['phiD'] = data['phi'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['phiD'] = data_test['phi'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vD'] = data['v'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['vD'] = data_test['v'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sm.tsa.ARIMA(endog=data['p'].values, exog=data['phiD'].values, order=(30, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test = sm.tsa.ARIMA(endog=data_test['p'].values, exog=data_test['phiD'].values, order=(10, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_30 = m.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AM (10, 0, 0)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(m.predict(results_10.params)[:150], label='pred')\n",
    "plt.plot(data['p'].values[:150], label='true')\n",
    "plt.legend(loc='best', fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = [np.sqrt(np.sum((t - p) ** 2)) / np.sqrt(np.sum(t ** 2)) \\\n",
    "       for t, p in zip(data['p'].values[:len(data['p'].values) // 151 * 151].reshape((len(data['p'].values) // 151, 151)),\n",
    "                       m.predict(results_10.params)[:len(data['p'].values) // 151 * 151].reshape((len(data['p'].values) // 151, 151)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(['RMSE',\n",
    "                 'mean %.4f' % np.mean(err).round(4),\n",
    "                 'median %.4f' % np.median(err).round(4),\n",
    "                 'max %.4f' % np.max(err).round(4),\n",
    "                 'min %.4f' % np.min(err).round(4),\n",
    "                 '95%% percentile %.4f' % np.percentile(err, 95).round(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AM (30, 0, 0)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(m.predict(results_30.params)[:150], label='pred')\n",
    "plt.plot(data['p'].values[:150], label='true')\n",
    "plt.legend(loc='best', fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = [np.sqrt(np.sum((t - p) ** 2)) / np.sqrt(np.sum(t ** 2)) \\\n",
    "       for t, p in zip(data['p'].values[:len(data['p'].values) // 151 * 151].reshape((len(data['p'].values) // 151, 151)),\n",
    "                       m.predict(results_30.params)[:len(data['p'].values) // 151 * 151].reshape((len(data['p'].values) // 151, 151)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(['RMSE',\n",
    "                 'mean %.4f' % np.mean(err).round(4),\n",
    "                 'median %.4f' % np.median(err).round(4),\n",
    "                 'max %.4f' % np.max(err).round(4),\n",
    "                 'min %.4f' % np.min(err).round(4),\n",
    "                 '95%% percentile %.4f' % np.percentile(err, 95).round(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
